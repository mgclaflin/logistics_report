{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c233777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.io\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# Initialize notebook for offline mode so it doesnt call plotly API\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "file_path = 'input file path'\n",
    "# importing parts data\n",
    "\n",
    "parts_data = pd.read_excel(file_path + 'Import_Data.xlsx', sheet_name = 'PARTS_DATA')\n",
    "parts_data = parts_data.drop(columns = ['Item', 'Release No.', 'Deletion indicator', '(Auto) Unloading Point',\n",
    "                                       'Release Creation Profile', 'Plant', 'GR processing time (sched. line)',\n",
    "                                       'Short Text', 'Order Unit', 'Gross Weight', 'MRP Area', 'Storage location', \n",
    "                                       'Weight unit', 'Planning Calendar', 'Lot Sizing Procedure', 'GR processing time (MRP)',\n",
    "                                       'Rounding value', 'Cum. Received Qty', 'Release Transmission Date', 'Last D. Note No.',\n",
    "                                       'Last GR Quantity', 'Date of Last GR', 'Target quantity', 'Base Unit of Measure', \n",
    "                                       'Load carrier', 'Vendor', 'Purchasing Group', 'Search Term', 'Country', 'Carrier', 'Carriername', \n",
    "                                       'Loading Group'])\n",
    "parts_data.rename(columns = {'Name' : 'Supplier', 'Goods Supplier' : 'Supplier Code'}, inplace=True)\n",
    "\n",
    "\n",
    "# importing Transit Time\n",
    "transit_time = pd.read_excel(file_path + 'Import_Data.xlsx', sheet_name = 'Transit_Time')\n",
    "transit_time.reset_index()\n",
    "transit_time = transit_time.drop(columns = ['Supplier'])\n",
    "\n",
    "\n",
    "# importing and prepping eket data (QuantityS)\n",
    "\n",
    "test_eket = pd.read_excel(file_path + 'Import_Data.xlsx', sheet_name = 'EKET')\n",
    "test_eket = test_eket.drop(columns = ['Item', 'Schedule Line', 'Quantity delivered'])\n",
    "test_eket.rename(columns={'Scheduled Quantity' : 'Quantities', 'Delivery date' : 'Date'}, inplace = True)\n",
    "\n",
    "eket = pd.merge(test_eket, parts_data, on = 'Purchasing Document')\n",
    "eket = eket.drop(columns = ['Purchasing Document'])\n",
    "eket['CW'] = eket['Date'].dt.week\n",
    "df_eket_part_sum = eket\n",
    "\n",
    "\n",
    "# importing and prepping ekes data (QuantityD)\n",
    "\n",
    "test_ekes = pd.read_excel(file_path + 'Import_Data.xlsx', sheet_name = 'EKES')\n",
    "test_ekes = test_ekes.drop(columns = ['Item', 'Sequential Number', 'Confirm. Category', 'Deliv. Date Category', 'Time-Spot',\n",
    "                                     'Delivery Date', 'Creation Time', 'Qty Reduced (MRP)', 'Creation indicator', \n",
    "                                     'Deletion Indicator', 'MRP-Relevant', 'Reference', 'Delivery', 'Item.1', 'Mfr part profile',\n",
    "                                     'No. Rem./Expediters', 'Batch', 'HigherLevelItemBatch', 'Sequential Number.1', 'In Plant',\n",
    "                                      'Delivery.1', 'Item.2', 'Handover Date', 'Handover Time', 'Stock Segment',\n",
    "                                      'CW Qty in Order Confirmation', 'CW MRP Reduced Quantity', 'Data Filter Value for Data Aging',\n",
    "                                      'Allocated Stock Quantity', 'Original Quantity'])\n",
    "test_ekes.rename(columns = {'MPN material' : 'Material', 'Quantity' : 'QuantityD', 'Creation Date' : 'Date'}, inplace = True)\n",
    "\n",
    "ekes = pd.merge(test_ekes, parts_data, on = 'Purchasing Document')\n",
    "ekes = ekes.drop(columns = ['Material_y'])\n",
    "ekes = ekes.rename(columns = {'Material_x' : 'Material'})\n",
    "ekes = ekes.drop(columns = ['Purchasing Document'])\n",
    "ekes = pd.merge(ekes, transit_time, on = 'Supplier Code')\n",
    "ekes['Date'] = pd.to_datetime(ekes['Date'])\n",
    "\n",
    "index = 0 \n",
    "for ind in ekes.index:\n",
    "    date = ekes.loc[index, 'Date']\n",
    "    temp = ekes.loc[index, 'Transit Time']\n",
    "    new_date = date + pd.offsets.BDay(temp)\n",
    "    ekes.at[index, 'New Date'] = new_date\n",
    "    index = index + 1\n",
    "ekes = ekes.drop(columns = ['Date'])\n",
    "ekes = ekes.rename(columns = {'New Date' : 'Date'})\n",
    "ekes['CW'] = ekes['Date'].dt.week\n",
    "ekes = ekes.drop(columns = ['Transit Time'])\n",
    "df_ekes_part_sum = ekes\n",
    "\n",
    "\n",
    "#check 1\n",
    "\n",
    "# sorting df by supplier, cw, material, and date\n",
    "frames_eket = [df_eket_part_sum, df_ekes_part_sum]\n",
    "result_df = pd.concat(frames_eket, sort=True)\n",
    "result_df.QuantityD = result_df.QuantityD.fillna(0)\n",
    "result_df.QuantityS = result_df.QuantityS.fillna(0)\n",
    "grouped_date_df = result_df.groupby(['Supplier', 'Supplier Code', 'CW', 'Material', 'Date']).sum().reset_index()\n",
    "\n",
    "supplier_data = grouped_date_df.copy()\n",
    "supplier_data = supplier_data.rename(columns={'QuantityD' : 'Quantity_Delivered', 'QuantityS' : 'Quantity_Scheduled'})\n",
    "\n",
    "grouped_date_df.loc[grouped_date_df['QuantityS'] == grouped_date_df['QuantityD'], 'Part Indicator'] = 1\n",
    "grouped_date_df.loc[grouped_date_df['QuantityS'] > grouped_date_df['QuantityD'], 'Part Indicator'] = 0\n",
    "grouped_date_df.loc[grouped_date_df['QuantityS'] < grouped_date_df['QuantityD'], 'Part Indicator'] = 1\n",
    "\n",
    "grouped_date_df_count = grouped_date_df.groupby(by = ['Supplier', 'Supplier Code', 'CW', 'Material']).count().reset_index()\n",
    "grouped_date_df_count.rename(columns = {'Date': 'Material_Shipments'}, inplace = True)\n",
    "grouped_date_df_count = grouped_date_df_count[['Supplier', 'Supplier Code', 'CW', 'Material', 'Material_Shipments']]\n",
    "\n",
    "grouped_date_df_sum = grouped_date_df.groupby(by = ['Supplier','Supplier Code', 'CW','Material','Part Indicator']).sum().reset_index()\n",
    "grouped_date_df_sum = grouped_date_df_sum[['Supplier', 'Supplier Code', 'CW', 'Material', 'Part Indicator']]\n",
    "grouped_date_df_sum.rename(columns = {'Part Indicator': 'Ontime/Early_Deliveries'}, inplace = True)\n",
    "grouped_date_df_sum['Ontime/Early_Deliveries'] = grouped_date_df_sum['Ontime/Early_Deliveries'].astype(int)\n",
    "\n",
    "grouped_date_df_merge = grouped_date_df_count.merge(grouped_date_df_sum, how = 'left', on = ['Supplier', 'Supplier Code',\n",
    "                                                                                             'CW', 'Material'])\n",
    "grouped_date_df_merge['Ontime %'] = grouped_date_df_merge['Ontime/Early_Deliveries']/grouped_date_df_merge['Material_Shipments'] * 100\n",
    "grouped_date_df_merge['Ontime %'] = grouped_date_df_merge['Ontime %'].astype(int)\n",
    "grouped_date_df_merge\n",
    "\n",
    "\n",
    "# Finalize Report df with all info to export\n",
    "\n",
    "check_one = grouped_date_df_merge\n",
    "Fcheck_one = check_one.groupby(by = ['Supplier', 'Supplier Code', 'CW']).mean().reset_index()\n",
    "Fcheck_one = Fcheck_one.drop(columns = ['Material_Shipments', 'Ontime/Early_Deliveries'])\n",
    "\n",
    "# seperating grouped_date_df_merge by supplier to export\n",
    "\n",
    "# sorting suppliers dfs\n",
    "def sortC1_by_supplier(supplier_name):\n",
    "    df = grouped_date_df_merge.loc[grouped_date_df_merge['Supplier'] == supplier_name]\n",
    "    return df\n",
    "\n",
    "#Completing the first delivery checks for all suppliers \n",
    "sup1C1 = sortC1_by_supplier('Supplier 1')\n",
    "\n",
    "sup2C2 = sortC1_by_supplier('Supplier 2')\n",
    "\n",
    "sup3C1 = sortC1_by_supplier('Supplier 3')\n",
    "\n",
    "sup4C1 = sortC1_by_supplier('Supplier 4')\n",
    "\n",
    "sup5C1 = sortC1_by_supplier('Supplier 5')\n",
    "\n",
    "sup6C1 = sortC1_by_supplier('Supplier 6')\n",
    "\n",
    "sup7C1 = sortC1_by_supplier('Supplier 7')\n",
    "\n",
    "sup8C1 = sortC1_by_supplier('Supplier 8')\n",
    "\n",
    "sup9C1 = sortC1_by_supplier('Supplier 9')\n",
    "\n",
    "\n",
    "# exporting all check one dfs \n",
    "writer = pd.ExcelWriter(file_path + 'OnTime_Report.xlsx')\n",
    "Fcheck_one.to_excel(writer, 'Report')\n",
    "americanC1.to_excel(writer, 'Supplier 1')\n",
    "aptivC1.to_excel(writer, 'Supplier 2')\n",
    "CJC1.to_excel(writer, 'Supplier 3')\n",
    "continentalC1.to_excel(writer, 'Supplier 4')\n",
    "gsC1.to_excel(writer, 'Supplier 5')\n",
    "gentexC1.to_excel(writer, 'Supplier 6')\n",
    "hutchinsonC1.to_excel(writer, 'Supplier 7')\n",
    "joysonC1.to_excel(writer, 'Supplier 8')\n",
    "modineC1.to_excel(writer, 'Supplier 9')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "#merging dfs for check 2\n",
    "\n",
    "frames_eket = [eket, ekes]\n",
    "check_two = pd.concat(frames_eket, sort=True)\n",
    "check_two.QuantityD = check_two.QuantityD.fillna(0)\n",
    "check_two.QuantityS = check_two.QuantityS.fillna(0)\n",
    "\n",
    "\n",
    "# 'indicator' fucntion\n",
    "\n",
    "def indicator_func(df):\n",
    "    df.loc[df['Ontime %'] > 100, 'Indicator'] = \"Over Shipped\"\n",
    "    df.loc[df['Ontime %'] == 100, 'Indicator'] = \"Ontime Shipment\"\n",
    "    df.loc[df['Ontime %'] < 100, 'Indicator'] = \"Under Shipped\"\n",
    "    df.loc[df['QuantityS'] == 0, 'Indicator'] = 'No Shipments Scheduled'\n",
    "    return df\n",
    "        \n",
    "# 2nd ontime check\n",
    "\n",
    "check_two = check_two.groupby(['Supplier', 'Supplier Code', 'CW', 'Material']).sum().reset_index()\n",
    "check_two['Ontime %'] = ((check_two['QuantityD'])/check_two['QuantityS'])*100  \n",
    "check_two = indicator_func(check_two)\n",
    "check_two.loc[check_two['Ontime %'] > 100, 'Ontime %'] = 100\n",
    "Echeck_two = check_two\n",
    "check_two.drop(columns=['Indicator'])\n",
    "check_two = check_two.groupby(['Supplier', 'Supplier Code', 'CW']).mean().reset_index()\n",
    "check_two = indicator_func(check_two)\n",
    "check_two = check_two.drop(columns = ['QuantityD', 'QuantityS'])\n",
    "check_two['Ontime %'] = check_two['Ontime %'].astype(int)\n",
    "\n",
    "\n",
    "# sorting suppliers dfs\n",
    "\n",
    "def sortC2_by_supplier(supplier_name):\n",
    "    df = Echeck_two.loc[Echeck_two['Supplier'] == supplier_name]\n",
    "    return df\n",
    "\n",
    "#Completing the second delivery checks for all suppliers \n",
    "sup1C2 = sortC2_by_supplier('Supplier 1')\n",
    "\n",
    "sup2C2 = sortC2_by_supplier('Supplier 2')\n",
    "\n",
    "sup3C2 = sortC2_by_supplier('Supplier 3')\n",
    "\n",
    "sup4C2 = sortC2_by_supplier('Supplier 4')\n",
    "\n",
    "sup5C2 = sortC2_by_supplier('Supplier 5')\n",
    "\n",
    "sup6C2 = sortC2_by_supplier('Supplier 6')\n",
    "\n",
    "sup7C2 = sortC2_by_supplier('Supplier 7')\n",
    "\n",
    "sup8C2 = sortC2_by_supplier('Supplier 8')\n",
    "\n",
    "sup9C2 = sortC2_by_supplier('Supplier 9')\n",
    "\n",
    "\n",
    "# exporting all dfs\n",
    "writer = pd.ExcelWriter(file_path + 'New_Check.xlsx')\n",
    "check_two.to_excel(writer, 'Report')\n",
    "americanC2.to_excel(writer, 'Supplier 1')\n",
    "aptivC2.to_excel(writer, 'Supplier 2')\n",
    "CJC2.to_excel(writer, 'Supplier 3')\n",
    "continentalC2.to_excel(writer, 'Supplier 4')\n",
    "gsC2.to_excel(writer, 'Supplier 5')\n",
    "gentexC2.to_excel(writer, 'Supplier 6')\n",
    "hutchinsonC2.to_excel(writer, 'Supplier 7')\n",
    "joysonC2.to_excel(writer, 'Supplier 8')\n",
    "modineC2.to_excel(writer, 'Supplier 9')\n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
